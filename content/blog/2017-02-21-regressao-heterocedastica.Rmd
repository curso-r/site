---
title: "Modelando a variância da normal"
date: "2017-02-21T13:07:31+02:00"
tags: ["stan", "r", "bayes", "regressao"]
categories: ["r","bayes"]
banner: "img/banners/tidyverse.jpg"
author: ["Fernando"]
draft: TRUE
summary: "Verificar as suposições dos modelos é muito importante quando fazemos inferência estatística. Em particular, a suposição de homocedasticidade dos modelos de regressão linear é especialmente importante, pois influencia o cálculo de erros padrão, intervalos de confiança e valores-p. Neste post, vou mostrar três pacotes do R que ajustam modelos de regressão linear heterocedastica."
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, comment = '', error = FALSE)

library(magrittr)
```

Verificar as suposições dos modelos é muito importante quando fazemos inferência estatística. Em particular, a suposição de homocedasticidade dos modelos de regressão linear é especialmente importante, pois modifica o cálculo de erros padrão, intervalos de confiança e valores-p.

Neste post, vou mostrar três pacotes do R que ajustam modelos da forma

$$ Y_i = \beta_0 + \sum_{k=1}^p\beta_kx_{ik} + \epsilon_i, \ i = 1,\ldots,n$$

$$ \epsilon_{i} \sim \textrm{N}(0,\sigma_i), \ i = 1,\ldots,n \ \textrm{independentes, com }\sigma_i^2 = \alpha x_i^2.  $$

Além de mostrar como se faz, também vou ilustrar o desempenho dos pacotes em um exemplo simulado. Os modelo que gerará os dados do exemplo terá a seguinte forma funcional

$$ Y_i = \beta x_i + \epsilon_i, \ i = 1,...n $$
$$ \epsilon_i \sim N(0, \sigma_i)\text{ independentes, com }\sigma_i = \alpha\sqrt{|x_i|},$$

e os parâmetros do modelo serão os valores $\beta = 1$ e $\alpha = 4$. Nesse modelo, a heterocedasticidade do modelo faz com que os pontos desenhem um cone ao redor da reta de regressão.

```{r}

library(ggplot2)

N <- 1000

set.seed(11071995)
X <- sample((N/100):(N*3), N)
Y <- rnorm(N,X,4*sqrt(X))

qplot(X,Y) + 
  theme_bw(15) + 
  geom_point(color = 'darkorange')

X2 <- sqrt(X)
dataset <- data.frame(Y,X,X2)

```

### Usando o pacote `gamlss`

Quando ajusta-se um GAMLSS, você pode modelar os parâmetros de locação, escala e curtose ao mesmo tempo em que escolhe a distribuição dos dados dentre uma grande gama de opções. Escolhendo a distribuição normal e modelando apenas os parâmetros de locação e escala, o GAMLSS ajusta modelos lineares normais com heterocedasticidade.

No código abaixo, o parâmetro `formula = Y ~ X-1` indica que a função de regressão será constiuída por um preditor linear em `X` sem intercepto. Já o parâmetro `sigma;formula = ~X2-1` indica que o desvio padrão será modelado por um preditor linear em `X2` (ou raiz de `X`), também sem intercepto.

```{r}

library(gamlss)

fit_gamlss <- gamlss::gamlss(formula = Y ~ X-1,
                             sigma.formula = ~X2-1,
                             data = dataset,
                             family = NO())
```

Conforme descrito no sumário abaixo, a estimativa de alfa está muito abaixo do valor simulado.

```{r}
summary(fit_gamlss)
```

### Usando o pacote `dglm`

Quando ajusta-se um Modelo Linear Generalizado Duplo (MLGD em português e DGLM em inglês), você tem uma flexibilidade parecida com a de um GAMLSS. Entretanto, você não pode definir um modelo para a curtose.

O código abaixo, similar ao utilizado para ajustar o GAMLSS, ajustam um DGLM aos dados simulados.

```{r}
library(dglm)

fit <- dglm(Y~X-1, dformula = ~X2-1,data = dataset, family = gaussian, method = 'reml')
```

Novamente, verifica-se que o alfa estimado está muito distante do verdadeiro alfa.

```{r}
summary(fit)
```

### Usando o pacote `rstan`

[Stan](http://mc-stan.org/) é uma linguagem de programação voltada para descrever e manipular objetos probabilísticos. Essa linguagem foi projetada para tornar intuitivo e simples o ajuste de modelos probabilísticos. A forma de descrever os problemas é particularmente simples em inferência bayesiana. 

Uma das vantagens do `stan` é que ele possui várias interfaces para `R`. A mais básica é o `rstan`, que será utilizada aqui. 

Uma chamada a função `stan` possui dois componentes básicos:

- um parâmetro `model_code =`, que recebe o código na linguagem `stan` que descreve o modelo.
- um parâmetro `data =`, que recebe uma lista contendo os inputs do modelo, tais como dados coletados, parâmetros de distribuições a priori, etc.

Embora esse seja o mínimo que a função precisa, outras componentes também podem ser passadas. O parâmetro `verbose = FALSE` faz com que a função não imprima nada enquanto roda e o parâmetro `control = list(...)` passa uma lista de parâmetros de controle para o algoritmo de ajuste.

O retorno da função `stan()` é um objeto do tipo `stanfit`, que pode ser sumarizado normalmente, utilizando a função `summary()` e a função `plot()`.

O código abaixo ilustra a aplicação da função `stan()` ao nosso exemplo.

```{r, eval = FALSE}

library(rstan)

scode <- "data {
  int<lower=0> N;
  vector[N] y;
  vector[N] x;
}
parameters {
  real beta;
  real<lower=0> alpha;
}
model {
  beta ~ normal(0,10);
  alpha ~ gamma(1,1);

  y ~ normal(beta * x, alpha * sqrt(x));
}"

dados <- list(N = nrow(dataset), y = dataset$Y, x = dataset$X)

fit_stan <- rstan::stan(model_code = scode, verbose = FALSE, data = dados,
             control = list(adapt_delta = 0.99))
```

```{r, echo = F}
library(rstan)
fit_stan <- readRDS("fit_stan.rds")
```

A figura abaixo descreve os intervalos de credibilidade obtidos para cada parâmetro do modelo. O ponto central de cada intervalo representa as estimativas pontuais dos parâmetros. Como se nota, a estimativa do modelo bayesiano utilizando `stan` está muito mais próxima das anteriores.

```{r}
plot(fit_stan)
```